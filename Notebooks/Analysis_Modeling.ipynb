{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSZAaCbbBip6",
        "outputId": "6bd7c1d8-c51b-49be-f66c-ee9553fb8fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Dataset Shape: (50000, 11)\n",
            "\n",
            "üìã Columns: ['Model', 'Year', 'Region', 'Color', 'Fuel_Type', 'Transmission', 'Engine_Size_L', 'Mileage_KM', 'Price_USD', 'Sales_Volume', 'Sales_Classification']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('all_cars_cleaned.csv')\n",
        "\n",
        "print(\"üìä Dataset Shape:\", df.shape)\n",
        "print(\"\\nüìã Columns:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create advanced features\n",
        "def create_modeling_features(df):\n",
        "    df_fe = df.copy()\n",
        "\n",
        "    # 1. Age of car\n",
        "    df_fe['Car_Age'] = 2024 - df_fe['Year']\n",
        "\n",
        "    # 2. Price per liter (efficiency metric)\n",
        "    df_fe['Price_Per_Liter'] = df_fe['Price_USD'] / df_fe['Engine_Size_L']\n",
        "\n",
        "    # 3. Mileage per year\n",
        "    df_fe['Mileage_Per_Year'] = df_fe['Mileage_KM'] / (2024 - df_fe['Year'] + 1)\n",
        "\n",
        "    # 4. Premium flag\n",
        "    premium_models = ['7 Series', 'M Series', 'i8']\n",
        "    df_fe['Is_Premium'] = df_fe['Model'].isin(premium_models).astype(int)\n",
        "\n",
        "    # 5. Regional economic indicator (proxy)\n",
        "    region_price_avg = df_fe.groupby('Region')['Price_USD'].mean()\n",
        "    df_fe['Region_Price_Index'] = df_fe['Region'].map(region_price_avg)\n",
        "\n",
        "    # 6. Series category\n",
        "    df_fe['Series_Category'] = df_fe['Model'].apply(lambda x:\n",
        "        '3 Series' if '3 SERIES' in str(x).upper() else\n",
        "        '5 Series' if '5 SERIES' in str(x).upper() else\n",
        "        '7 Series' if '7 SERIES' in str(x).upper() else\n",
        "        'X Series' if str(x).upper().startswith('X') else\n",
        "        'M Series' if str(x).upper().startswith('M') else\n",
        "        'i Series' if str(x).upper().startswith('I') else 'Other'\n",
        "    )\n",
        "\n",
        "    # 7. Seasonality (quarter based on year)\n",
        "    df_fe['Year_Quarter'] = (df_fe['Year'] % 4) + 1\n",
        "\n",
        "    return df_fe\n",
        "\n",
        "df_model = create_modeling_features(df)\n",
        "print(\"‚úÖ Feature engineering completed!\")\n",
        "print(\"New features:\", [col for col in df_model.columns if col not in df.columns])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaKqNT9AB8yQ",
        "outputId": "0894c5a4-8206-46cc-8126-00049a7eaf1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feature engineering completed!\n",
            "New features: ['Car_Age', 'Price_Per_Liter', 'Mileage_Per_Year', 'Is_Premium', 'Region_Price_Index', 'Series_Category', 'Year_Quarter']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features for modeling\n",
        "features = ['Year', 'Engine_Size_L', 'Mileage_KM', 'Car_Age', 'Price_Per_Liter',\n",
        "           'Mileage_Per_Year', 'Is_Premium', 'Region_Price_Index', 'Year_Quarter']\n",
        "\n",
        "categorical_features = ['Region', 'Color', 'Fuel_Type', 'Transmission', 'Series_Category']\n",
        "\n",
        "# Prepare feature matrix\n",
        "X = df_model[features].copy()\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for col in categorical_features:\n",
        "    if col in df_model.columns:\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(df_model[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "# Target variables\n",
        "y_price = df_model['Price_USD']\n",
        "y_sales = df_model['Sales_Volume']\n",
        "y_classification = df_model['Sales_Classification']\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Target variables:\")\n",
        "print(\"- Price_USD:\", y_price.shape)\n",
        "print(\"- Sales_Volume:\", y_sales.shape)\n",
        "print(\"- Sales_Classification:\", y_classification.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYiJYrXGCAko",
        "outputId": "1baa195a-e210-4bc9-8479-715ad1344e82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (50000, 14)\n",
            "Target variables:\n",
            "- Price_USD: (50000,)\n",
            "- Sales_Volume: (50000,)\n",
            "- Sales_Classification: (50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*50)\n",
        "print(\"üè∑Ô∏è PRICE PREDICTION MODELING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Split data for price prediction\n",
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
        "    X, y_price, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler_p = StandardScaler()\n",
        "X_train_scaled_p = scaler_p.fit_transform(X_train_p)\n",
        "X_test_scaled_p = scaler_p.transform(X_test_p)\n",
        "\n",
        "# Define models for price prediction\n",
        "price_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0),\n",
        "    'Lasso Regression': Lasso(alpha=0.1),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate price models\n",
        "price_results = {}\n",
        "\n",
        "for name, model in price_models.items():\n",
        "    if name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression']:\n",
        "        model.fit(X_train_scaled_p, y_train_p)\n",
        "        y_pred = model.predict(X_test_scaled_p)\n",
        "    else:\n",
        "        model.fit(X_train_p, y_train_p)\n",
        "        y_pred = model.predict(X_test_p)\n",
        "\n",
        "    mae = mean_absolute_error(y_test_p, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_p, y_pred))\n",
        "    r2 = r2_score(y_test_p, y_pred)\n",
        "\n",
        "    price_results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n",
        "    print(f\"{name:20} | MAE: ${mae:,.0f} | RMSE: ${rmse:,.0f} | R¬≤: {r2:.3f}\")\n",
        "\n",
        "# Find best price model\n",
        "best_price_model = max(price_results.items(), key=lambda x: x[1]['R2'])\n",
        "print(f\"\\nüéØ BEST PRICE MODEL: {best_price_model[0]} (R¬≤: {best_price_model[1]['R2']:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrxPnFcFCDkf",
        "outputId": "e8f95f27-0056-43aa-cc3e-6a9b46fd9c7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "üè∑Ô∏è PRICE PREDICTION MODELING\n",
            "==================================================\n",
            "Linear Regression    | MAE: $8,650 | RMSE: $11,034 | R¬≤: 0.820\n",
            "Ridge Regression     | MAE: $8,650 | RMSE: $11,034 | R¬≤: 0.820\n",
            "Lasso Regression     | MAE: $8,650 | RMSE: $11,034 | R¬≤: 0.820\n",
            "Random Forest        | MAE: $55 | RMSE: $84 | R¬≤: 1.000\n",
            "Gradient Boosting    | MAE: $1,280 | RMSE: $1,732 | R¬≤: 0.996\n",
            "XGBoost              | MAE: $380 | RMSE: $515 | R¬≤: 1.000\n",
            "\n",
            "üéØ BEST PRICE MODEL: Random Forest (R¬≤: 1.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìà SALES VOLUME PREDICTION MODELING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Split data for sales prediction\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
        "    X, y_sales, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features for sales\n",
        "scaler_s = StandardScaler()\n",
        "X_train_scaled_s = scaler_s.fit_transform(X_train_s)\n",
        "X_test_scaled_s = scaler_s.transform(X_test_s)\n",
        "\n",
        "# Define models for sales prediction\n",
        "sales_models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
        "    'Linear Regression': LinearRegression()\n",
        "}\n",
        "\n",
        "# Train and evaluate sales models\n",
        "sales_results = {}\n",
        "\n",
        "for name, model in sales_models.items():\n",
        "    if name == 'Linear Regression':\n",
        "        model.fit(X_train_scaled_s, y_train_s)\n",
        "        y_pred = model.predict(X_test_scaled_s)\n",
        "    else:\n",
        "        model.fit(X_train_s, y_train_s)\n",
        "        y_pred = model.predict(X_test_s)\n",
        "\n",
        "    mae = mean_absolute_error(y_test_s, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_s, y_pred))\n",
        "    r2 = r2_score(y_test_s, y_pred)\n",
        "\n",
        "    sales_results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n",
        "    print(f\"{name:20} | MAE: {mae:,.0f} units | RMSE: {rmse:,.0f} | R¬≤: {r2:.3f}\")\n",
        "\n",
        "# Find best sales model\n",
        "best_sales_model = max(sales_results.items(), key=lambda x: x[1]['R2'])\n",
        "print(f\"\\nüéØ BEST SALES MODEL: {best_sales_model[0]} (R¬≤: {best_sales_model[1]['R2']:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4K2Xs5ICG5z",
        "outputId": "b3e8193d-c79e-4491-b71c-c3eefc9b0904"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üìà SALES VOLUME PREDICTION MODELING\n",
            "==================================================\n",
            "Random Forest        | MAE: 2,502 units | RMSE: 2,911 | R¬≤: -0.037\n",
            "Gradient Boosting    | MAE: 2,479 units | RMSE: 2,863 | R¬≤: -0.003\n",
            "XGBoost              | MAE: 2,524 units | RMSE: 2,935 | R¬≤: -0.054\n",
            "Linear Regression    | MAE: 2,477 units | RMSE: 2,859 | R¬≤: -0.000\n",
            "\n",
            "üéØ BEST SALES MODEL: Linear Regression (R¬≤: -0.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîç FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Train best models for feature importance\n",
        "best_rf_price = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "best_rf_price.fit(X_train_p, y_train_p)\n",
        "\n",
        "best_rf_sales = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "best_rf_sales.fit(X_train_s, y_train_s)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance_price = pd.DataFrame({\n",
        "    'feature': features + categorical_features,\n",
        "    'importance_price': best_rf_price.feature_importances_\n",
        "}).sort_values('importance_price', ascending=False)\n",
        "\n",
        "feature_importance_sales = pd.DataFrame({\n",
        "    'feature': features + categorical_features,\n",
        "    'importance_sales': best_rf_sales.feature_importances_\n",
        "}).sort_values('importance_sales', ascending=False)\n",
        "\n",
        "print(\"üí∞ PRICE PREDICTION - Top Features:\")\n",
        "for _, row in feature_importance_price.head(10).iterrows():\n",
        "    print(f\"  {row['feature']:25} | Importance: {row['importance_price']:.3f}\")\n",
        "\n",
        "print(\"\\nüìà SALES PREDICTION - Top Features:\")\n",
        "for _, row in feature_importance_sales.head(10).iterrows():\n",
        "    print(f\"  {row['feature']:25} | Importance: {row['importance_sales']:.3f}\")\n",
        "\n",
        "# Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Price feature importance\n",
        "ax1.barh(feature_importance_price['feature'].head(10),\n",
        "         feature_importance_price['importance_price'].head(10))\n",
        "ax1.set_title('Feature Importance - Price Prediction', fontweight='bold')\n",
        "ax1.set_xlabel('Importance')\n",
        "\n",
        "# Sales feature importance\n",
        "ax2.barh(feature_importance_sales['feature'].head(10),\n",
        "         feature_importance_sales['importance_sales'].head(10))\n",
        "ax2.set_title('Feature Importance - Sales Prediction', fontweight='bold')\n",
        "ax2.set_xlabel('Importance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmzMTOEmC-HA",
        "outputId": "c3042ea0-4308-417f-df44-1a7cec69728d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üîç FEATURE IMPORTANCE ANALYSIS\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üë• CUSTOMER SEGMENTATION ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Features for clustering\n",
        "cluster_features = ['Price_USD', 'Engine_Size_L', 'Mileage_KM', 'Year', 'Sales_Volume']\n",
        "X_cluster = df_model[cluster_features].copy()\n",
        "\n",
        "# Scale features for clustering\n",
        "scaler_cluster = StandardScaler()\n",
        "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
        "\n",
        "# Determine optimal number of clusters using elbow method\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_cluster_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), wcss, marker='o')\n",
        "plt.title('Elbow Method for Optimal Clusters', fontweight='bold')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Apply K-means with optimal clusters\n",
        "optimal_clusters = 4  # Based on elbow method\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)\n",
        "df_model['Cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
        "\n",
        "# Analyze clusters\n",
        "cluster_analysis = df_model.groupby('Cluster').agg({\n",
        "    'Price_USD': ['mean', 'std'],\n",
        "    'Engine_Size_L': 'mean',\n",
        "    'Year': 'mean',\n",
        "    'Sales_Volume': 'mean',\n",
        "    'Model': lambda x: x.mode()[0],\n",
        "    'Region': lambda x: x.mode()[0]\n",
        "}).round(2)\n",
        "\n",
        "print(\"üîç CUSTOMER SEGMENTS:\")\n",
        "print(cluster_analysis)\n",
        "\n",
        "# Visualize clusters with PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_cluster_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df_model['Cluster'], cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(scatter)\n",
        "plt.title('Customer Segments Visualization (PCA)', fontweight='bold')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "\n",
        "# Add segment descriptions\n",
        "segment_descriptions = {\n",
        "    0: \"Budget Market\",\n",
        "    1: \"Premium Luxury\",\n",
        "    2: \"Performance\",\n",
        "    3: \"Mid-Range Family\"\n",
        "}\n",
        "\n",
        "for cluster in range(optimal_clusters):\n",
        "    cluster_points = X_pca[df_model['Cluster'] == cluster]\n",
        "    if len(cluster_points) > 0:\n",
        "        plt.annotate(segment_descriptions.get(cluster, f'Segment {cluster}'),\n",
        "                    (cluster_points[:, 0].mean(), cluster_points[:, 1].mean()),\n",
        "                    xytext=(10, 10), textcoords='offset points',\n",
        "                    fontweight='bold', fontsize=9,\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.7))\n",
        "\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dfGq1joMDAlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚è∞ TIME SERIES FORECASTING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Prepare time series data\n",
        "yearly_data = df_model.groupby('Year').agg({\n",
        "    'Sales_Volume': 'sum',\n",
        "    'Price_USD': 'mean',\n",
        "    'Engine_Size_L': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Simple time series forecasting using linear regression\n",
        "X_time = yearly_data[['Year']]\n",
        "y_time = yearly_data['Sales_Volume']\n",
        "\n",
        "# Add lag features for better time series prediction\n",
        "yearly_data['Sales_Lag1'] = yearly_data['Sales_Volume'].shift(1)\n",
        "yearly_data['Sales_Lag2'] = yearly_data['Sales_Volume'].shift(2)\n",
        "yearly_data = yearly_data.dropna()\n",
        "\n",
        "X_time_lag = yearly_data[['Year', 'Sales_Lag1', 'Sales_Lag2']]\n",
        "y_time_lag = yearly_data['Sales_Volume']\n",
        "\n",
        "# Train time series model\n",
        "ts_model = LinearRegression()\n",
        "ts_model.fit(X_time_lag, y_time_lag)\n",
        "\n",
        "# Forecast next year\n",
        "last_year = yearly_data['Year'].max()\n",
        "last_sales = yearly_data['Sales_Volume'].iloc[-1]\n",
        "second_last_sales = yearly_data['Sales_Volume'].iloc[-2]\n",
        "\n",
        "next_year_pred = ts_model.predict([[last_year + 1, last_sales, second_last_sales]])[0]\n",
        "\n",
        "print(f\"üìÖ TIME SERIES ANALYSIS:\")\n",
        "print(f\"‚Ä¢ Historical data: {len(yearly_data)} years\")\n",
        "print(f\"‚Ä¢ Last year sales: {last_sales:,.0f} units\")\n",
        "print(f\"‚Ä¢ Forecast for {last_year + 1}: {next_year_pred:,.0f} units\")\n",
        "print(f\"‚Ä¢ Projected growth: {(next_year_pred/last_sales - 1)*100:+.1f}%\")\n",
        "\n",
        "# Plot time series forecast\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(yearly_data['Year'], yearly_data['Sales_Volume'], 'o-', linewidth=2,\n",
        "         label='Historical Sales', color='#0032A0')\n",
        "\n",
        "# Add forecast point\n",
        "plt.plot(last_year + 1, next_year_pred, 'ro', markersize=10,\n",
        "         label=f'Forecast {last_year + 1}')\n",
        "\n",
        "plt.title('BMW Sales Time Series & Forecast', fontweight='bold')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Sales Volume')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hv-Jz5AXDCEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚öôÔ∏è HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Using smaller subset for faster tuning\n",
        "X_tune = X.sample(1000, random_state=42) if len(X) > 1000 else X\n",
        "y_tune = y_price.loc[X_tune.index] if len(X) > 1000 else y_price\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(\n",
        "    rf, param_grid, cv=3, scoring='r2',\n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "\n",
        "print(\"Tuning Random Forest...\")\n",
        "grid_search.fit(X_tune, y_tune)\n",
        "\n",
        "print(f\"üéØ BEST PARAMETERS:\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "print(f\"Best CV Score (R¬≤): {grid_search.best_score_:.3f}\")\n",
        "\n",
        "# Train with best parameters\n",
        "best_rf_tuned = grid_search.best_estimator_\n",
        "best_rf_tuned.fit(X_train_p, y_train_p)\n",
        "y_pred_tuned = best_rf_tuned.predict(X_test_p)\n",
        "\n",
        "r2_tuned = r2_score(y_test_p, y_pred_tuned)\n",
        "print(f\"Tuned model test R¬≤: {r2_tuned:.3f}\")"
      ],
      "metadata": {
        "id": "LufwDhEwDDm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ MODEL DEPLOYMENT PREPARATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Save best models\n",
        "model_artifacts = {\n",
        "    'price_scaler': scaler_p,\n",
        "    'sales_scaler': scaler_s,\n",
        "    'best_price_model': best_rf_price,\n",
        "    'best_sales_model': best_rf_sales,\n",
        "    'kmeans_model': kmeans,\n",
        "    'cluster_scaler': scaler_cluster,\n",
        "    'label_encoders': label_encoders,\n",
        "    'feature_names': features + categorical_features\n",
        "}\n",
        "\n",
        "# Save models\n",
        "joblib.dump(model_artifacts, 'bmw_models.pkl')\n",
        "\n",
        "# Save feature importance\n",
        "feature_importance_dict = {\n",
        "    'price_features': feature_importance_price.to_dict(),\n",
        "    'sales_features': feature_importance_sales.to_dict()\n",
        "}\n",
        "\n",
        "with open('feature_importance.json', 'w') as f:\n",
        "    json.dump(feature_importance_dict, f, indent=2)\n",
        "\n",
        "# Create prediction function\n",
        "def predict_bmw_price(features_dict):\n",
        "    \"\"\"Predict BMW price based on features\"\"\"\n",
        "    # Load model artifacts\n",
        "    artifacts = joblib.load('bmw_models.pkl')\n",
        "\n",
        "    # Prepare input features\n",
        "    input_features = []\n",
        "    for feature in artifacts['feature_names']:\n",
        "        if feature in features_dict:\n",
        "            input_features.append(features_dict[feature])\n",
        "        else:\n",
        "            input_features.append(0)  # Default value\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = artifacts['best_price_model'].predict([input_features])[0]\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Example prediction\n",
        "example_car = {\n",
        "    'Year': 2022,\n",
        "    'Engine_Size_L': 3.0,\n",
        "    'Mileage_KM': 15000,\n",
        "    'Car_Age': 2,\n",
        "    'Region': 'North America',\n",
        "    'Series_Category': '5 Series'\n",
        "}\n",
        "\n",
        "predicted_price = predict_bmw_price(example_car)\n",
        "print(f\"üí∞ EXAMPLE PREDICTION:\")\n",
        "print(f\"Car features: {example_car}\")\n",
        "print(f\"Predicted price: ${predicted_price:,.2f}\")\n",
        "\n",
        "print(\"\\n‚úÖ MODELING COMPLETED!\")\n",
        "print(\"üìÅ Saved files:\")\n",
        "print(\"   - bmw_models.pkl (trained models)\")\n",
        "print(\"   - feature_importance.json (feature analysis)\")\n",
        "print(\"   - Ready for deployment! üöÄ\")"
      ],
      "metadata": {
        "id": "oGtANc9ADFcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üí° BUSINESS INSIGHTS FROM MODELING ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"üéØ PREDICTION PERFORMANCE:\")\n",
        "print(f\"‚Ä¢ Price Prediction R¬≤: {best_price_model[1]['R2']:.3f}\")\n",
        "print(f\"‚Ä¢ Sales Prediction R¬≤: {best_sales_model[1]['R2']:.3f}\")\n",
        "\n",
        "print(\"\\nüîë KEY DRIVERS IDENTIFIED:\")\n",
        "print(\"üí∞ PRICE DRIVERS:\")\n",
        "for feature in feature_importance_price['feature'].head(3):\n",
        "    print(f\"  - {feature}\")\n",
        "\n",
        "print(\"üìà SALES DRIVERS:\")\n",
        "for feature in feature_importance_sales['feature'].head(3):\n",
        "    print(f\"  - {feature}\")\n",
        "\n",
        "print(f\"\\nüë• CUSTOMER SEGMENTS: {optimal_clusters} segments identified\")\n",
        "print(\"  1. Budget Market - Price sensitive customers\")\n",
        "print(\"  2. Premium Luxury - High-end buyers\")\n",
        "print(\"  3. Performance - Sport model enthusiasts\")\n",
        "print(\"  4. Mid-Range Family - Balanced features\")\n",
        "\n",
        "print(f\"\\nüìÖ SALES FORECAST: {next_year_pred:,.0f} units in {last_year + 1}\")\n",
        "\n",
        "print(\"\\nüöÄ RECOMMENDED ACTIONS:\")\n",
        "print(\"  1. Focus marketing on key price drivers\")\n",
        "print(\"  2. Optimize inventory for high-sales features\")\n",
        "print(\"  3. Develop targeted campaigns for each customer segment\")\n",
        "print(\"  4. Use price predictions for dynamic pricing strategy\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "0098bbYlDHxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}